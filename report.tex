\documentclass[12pt]{article}
\usepackage{fullpage,mathpazo,amsfonts,nicefrac}

\usepackage{kpfonts}
%\usepackage{fontspec}
%\setmainfont{Hoefler Text}

\usepackage{media9}

\usepackage{graphicx}

\usepackage{pgfplots}
\usepackage{pgfplotstable}
\usepackage{tikz}
\usetikzlibrary{arrows,automata,mindmap,shapes,positioning,patterns,snakes,calc}

\pgfplotsset{every x tick label/.append style={font=\small, yshift=0.2ex}}
\pgfplotsset{every y tick label/.append style={font=\small, xshift=0.2ex}}

\usepackage{multirow}

\usepackage{amsmath,amsthm,mathrsfs,bm}
\usepackage{amssymb}% math symbols
\usepackage{mathtools}
\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
\DeclarePairedDelimiter{\floor}{\lfloor}{\rfloor}

\numberwithin{table}{section}

\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,
}
\usepackage{color}

% color
\definecolor{marron}{RGB}{60,30,10}
\definecolor{darkblue}{RGB}{0,0,80}
\definecolor{lightblue}{RGB}{80,80,80}
\definecolor{darkgreen}{RGB}{0,80,0}
\definecolor{darkgray}{RGB}{0,80,0}
\definecolor{darkred}{RGB}{80,0,0}
\definecolor{shadecolor}{rgb}{0.97,0.97,0.97}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{definition}{Definition}[section]
\newtheorem{axiom}{Axiom}[section]
\newtheorem{property}{Property}[section]
\newtheorem{proposition}{Proposition}[section]
\newtheorem{corollary}{Corollary}[section]
\newtheorem{condition}{Condition}[section]
\newtheorem{conclusion}{Conclusion}[section]
\newtheorem{assumption}{Assumption}[section]
\newtheorem{remark}{Remark}[section]
\newtheorem{problem}{Problem}[section]
\newtheorem{solution}{Solution}[section]

\renewcommand{\emptyset}{\varnothing}
\DeclareMathOperator*{\argmax}{\mathrm{\arg\max}}
\DeclareMathOperator*{\argmin}{\mathrm{\arg\min}}
\DeclareMathOperator*{\arginf}{\mathrm{\arg\inf}}
\DeclareMathOperator*{\argsup}{\mathrm{\arg\sup}}
\DeclareMathOperator{\sgn}{\mathrm{sign}}
\DeclareMathOperator{\ind}{\mathrm{I}}
\DeclareMathOperator{\complex}{\mathrm{O}}
\DeclareMathOperator{\diag}{\mathrm{diag}}
\DeclareMathOperator{\prob}{\mathrm{Pr}}
\DeclareMathOperator{\E}{\mathrm{E}}
\DeclareMathOperator{\var}{\mathrm{var}}
\DeclareMathOperator{\corr}{\mathrm{corr}}
\DeclareMathOperator{\cov}{\mathrm{cov}}
\DeclareMathOperator{\rand}{\mathrm{rand}}
\DeclareMathOperator{\vect}{\textit{vec}}
\DeclareMathOperator{\rank}{\textit{rank}}
\DeclareMathOperator{\tr}{\textit{tr}}

\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}

% Useful for algorithms
\newcommand{\alg}[1]{\textsc{\bfseries \footnotesize #1}}

% For derivatives
\newcommand{\deriv}[1]{\frac{\mathrm{d}}{\mathrm{d}x} (#1)}

% For partial derivatives
\newcommand{\pderiv}[2]{\frac{\partial}{\partial #1} (#2)}

% Integral dx
\newcommand{\dx}{\mathrm{d}x}


\renewcommand{\baselinestretch}{1.5}
\setlength{\parskip}{0.5em}

\usepackage{algpseudocode,algorithm,algorithmicx}
\newcommand*\Let[2]{\State #1 $\gets$ #2}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}

\setlength\parindent{0em}

\title{Credit Allocation}
% Created Apr 27, 2018
\author{~}

\begin{document}
\maketitle

\noindent

\section{Credit Allocation Problem}

\[
\textrm{PR}_j = \frac{1-d}{N} + d \sum_{k\in I_j} \frac{\textrm{PR}_k}{|O_k|}
\]
where $N$ is the total number of nodes, $I_j$ is the incoming nodes to $j$, $O_k$ is the outgoing nodes from $j$, $d \in(0,1)$ is the damping factor, it's the probability of following the out-links to the next node.

\section{Iterative Approach}
Let $\mathcal P=\{p_1,p_2,\ldots,p_m\}$ be the entire set of articles, $\mathcal A=\{a_1,a_2,\ldots,a_n\}$ be all the authors appeared in $\mathcal P$. Each author may have multiple works, and each paper may have multiple coauthors. Let $A_i$ be the coauthors of $p_i$. We assume that the credit of a paper is allocated among all the authors in $\mathcal A$. The credit allocation can be considered as the mechanism of intrinsic value allocation, reflecting the contribution, directly or indirectly from each researchers. Let $C\in \mathbb R^{n\times m}$ be the intrinsic credit allocation matrix of $m$ papers over $n$ authors.

The Shen-Barabasi credit allocation approach allocates credits based on the recognition from a community of the co-cited papers. The co-cited papers play as a committee, each of them has an independent credit allocation over the coauthors of the target paper. However, the credit allocation values the relative contribution from the coauthors in subject but completely ignoring other authors' contribution. The credit allocation is definitely inconsistent with the true allocation.

To construct an intrinsic credit allocation schema, we proposed an iterative approach based on the infrastructure of SB model. Let $S=(s_1,s_2,\ldots,s_m)$ be the strength matrix, and each column vector is defined as the strength vector in SB model, i.e. $s_i$ is the strength vector of paper $p_i$. The strength indicates the relevance of a pair of papers, and it's measured with the co-citation count. 

Based on SB model, we have $C=C S$, which is equivalent to solve from $C(S-I)=0$ the matrix $C$.
Also, we expect the credits allocated to non-authors being minimized. Let $B$ be the indicator matrix presenting that $b_{ij}=0$ if $a_i$ is a coauthor of $p_j$, otherwise $b_{ij}=1$. The minimization terms would be 
\[
\sum_{j=1}^m \sum_{i=1}^n c_{ij} b_{ij}=\textrm{tr}(B^T C).
\]
Integrating both components, we define the objective function
\[
L(C) = \|C(S-I)\|_F^2 + \textrm{tr}(B^T C)=\textrm{tr}[(S-I)^T C^T C(S-I)] + \textrm{tr}(B^T C).
\]
Obviously, we can compute the gradient 
\[
\begin{array}{rl}
\nabla_C L(C) & = \partial [\|C(S-I)\|_F^2 + \textrm{tr}(B^T C)]/\partial C\\
&=\partial \textrm{tr}[(S-I)^T C^T C(S-I)]/\partial C + B\\
&=2C(S-I)(S-I)^T + B.
\end{array}
\]
The matrix $(S-I)(S-I)^T$ is positive semi-definite. Let the gradient be zero, we directly solve the optimal credit allocation
\[
C=-B[(S-I)(S-I)^T]^{\dagger}/2,
\]
where $A^\dagger$ stands for the pseudo-inverse.

However, when the matrix is large, the pseudo-inverse computation may become very time-consuming. An alternative will be the iterative approach.

Let the initial guess $C_0$ be a column stochastic matrix, with each coauthor of the paper the same amount of credits. With the GD method, it's updated following the rule:
\[
C_t \leftarrow C_{t-1} + \alpha [2C_{t-1}(S-I)(S-I)^T + B],
\]
where $\alpha\in (0,1)$ is the learning rate.

%\bibliographystyle{unsrt}
\bibliographystyle{apalike}
\bibliography{references}

\end{document}